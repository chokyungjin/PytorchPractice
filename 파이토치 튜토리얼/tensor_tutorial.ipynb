{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "PyTorch가 무엇인가요?\n",
    "=======================\n",
    "\n",
    "Python 기반의 과학 연산 패키지로 다음과 같은 두 집단을 대상으로 합니다:\n",
    "\n",
    "- NumPy를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
    "- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우\n",
    "\n",
    "시작하기\n",
    "-----------\n",
    "\n",
    "Tensors\n",
    "^^^^^^^\n",
    "\n",
    "Tensor는 NumPy의 ndarray와 유사하며, 추가로 GPU를 사용한 연산 가속도 가능합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>초기화되지 않은 행렬이 선언되었지만, 사용하기 전에는 명확히 알려진 값을\n",
    "    포함하고 있지는 않습니다. 초기화되지 않은 행렬이 생성되면 그 시점에 할당된\n",
    "    메모리에 존재하던 값들이 초기값으로 나타납니다.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기화되지 않은 5x3 행렬을 생성합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6816e-44, 1.4013e-45, 6.6621e-18],\n",
      "        [2.1019e-44, 6.6621e-18, 1.4013e-45],\n",
      "        [2.5223e-44, 1.4013e-45, 6.6622e-18],\n",
      "        [2.9427e-44, 0.0000e+00, 0.0000e+00],\n",
      "        [3.3631e-44, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무작위로 초기화된 행렬을 생성합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8405, 0.6860, 0.4613],\n",
      "        [0.9893, 0.4796, 0.7299],\n",
      "        [0.1209, 0.8663, 0.7437],\n",
      "        [0.8565, 0.5135, 0.8011],\n",
      "        [0.8729, 0.7144, 0.3153]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtype이 long이고 0으로 채워진 행렬을 생성합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로부터 tensor를 직접 생성합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 존재하는 tensor를 바탕으로 tensor를 만듭니다. 이 메소드(method)들은\n",
    "사용자로부터 제공된 새로운 값이 없는 한, 입력 tensor의 속성들(예. dtype)을\n",
    "재사용합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.0080, -0.4983,  2.0852],\n",
      "        [-0.8870, -0.7617,  1.4127],\n",
      "        [-0.5358, -0.1012,  0.6958],\n",
      "        [-0.6081,  2.2782, -1.0955],\n",
      "        [-1.3438,  0.6458, -0.7458]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)      # new_* 메소드는 크기를 받습니다\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)    # dtype을 오버라이드(Override) 합니다!\n",
    "print(x)                                      # 결과는 동일한 크기를 갖습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬의 크기를 구합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.Size`` 는 사실 튜플(tuple)과 같으며, 모든 튜플 연산을 지원합니다.</p></div>\n",
    "\n",
    "연산(Operations)\n",
    "^^^^^^^^^^^^^^^^\n",
    "연산을 위한 여러가지 문법을 제공합니다. 다음 예제들을 통해 덧셈 연산을 살펴보겠습니다.\n",
    "\n",
    "덧셈: 문법1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4403, -0.4495,  2.6437],\n",
      "        [-0.0973, -0.4270,  1.6994],\n",
      "        [-0.2521,  0.6921,  1.6851],\n",
      "        [ 0.3182,  2.7931, -0.9170],\n",
      "        [-0.4352,  0.8427, -0.1489]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈: 문법2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4403, -0.4495,  2.6437],\n",
      "        [-0.0973, -0.4270,  1.6994],\n",
      "        [-0.2521,  0.6921,  1.6851],\n",
      "        [ 0.3182,  2.7931, -0.9170],\n",
      "        [-0.4352,  0.8427, -0.1489]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈: 결과 tensor를 인자로 제공\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4403, -0.4495,  2.6437],\n",
      "        [-0.0973, -0.4270,  1.6994],\n",
      "        [-0.2521,  0.6921,  1.6851],\n",
      "        [ 0.3182,  2.7931, -0.9170],\n",
      "        [-0.4352,  0.8427, -0.1489]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "덧셈: 바꿔치기(In-place) 방식\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4403, -0.4495,  2.6437],\n",
      "        [-0.0973, -0.4270,  1.6994],\n",
      "        [-0.2521,  0.6921,  1.6851],\n",
      "        [ 0.3182,  2.7931, -0.9170],\n",
      "        [-0.4352,  0.8427, -0.1489]])\n"
     ]
    }
   ],
   "source": [
    "# y에 x 더하기\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>바꿔치기(In-place) 방식으로 tensor의 값을 변경하는 연산은 ``_`` 를 접미사로\n",
    "    갖습니다.\n",
    "    예: ``x.copy_(y)``, ``x.t_()`` 는 ``x`` 를 변경합니다.</p></div>\n",
    "\n",
    "NumPy스러운 인덱싱 표기 방법을 사용할 수도 있습니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4983, -0.7617, -0.1012,  2.2782,  0.6458])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크기 변경: tensor의 크기(size)나 모양(shape)을 변경하고 싶다면 ``torch.view`` 를 사용합니다:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # -1은 다른 차원들을 사용하여 유추합니다.\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 tensor에 하나의 값만 존재한다면, ``.item()`` 을 사용하면 숫자 값을 얻을 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**더 읽을거리:**\n",
    "\n",
    "\n",
    "  전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산,\n",
    "  선형 대수, 난수(random number) 등과 같은 100가지 이상의 Tensor 연산은\n",
    "  `여기 <http://pytorch.org/docs/torch>`_ 에 설명되어 있습니다.\n",
    "\n",
    "NumPy 변환(Bridge)\n",
    "-------------------\n",
    "\n",
    "Torch Tensor를 NumPy 배열(array)로 변환하거나, 그 반대로 하는 것은 매우 쉽습니다.\n",
    "\n",
    "(CPU 상의) Torch Tensor와 NumPy 배열은 저장 공간을 공유하기 때문에,\n",
    "하나를 변경하면 다른 하나도 변경됩니다.\n",
    "\n",
    "Torch Tensor를 NumPy 배열로 변환하기\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy 배열의 값이 어떻게 변하는지 확인해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy 배열을 Torch Tensor로 변환하기\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "NumPy(np) 배열을 변경하면 Torch Tensor의 값도 자동 변경되는 것을 확인해보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CharTensor를 제외한 CPU 상의 모든 Tensor는 NumPy로의 변환을 지원하며,\n",
    "(NumPy에서 Tensor로의) 반대 변환도 지원합니다.\n",
    "\n",
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "``.to`` 메소드를 사용하여 Tensor를 어떠한 장치로도 옮길 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 코드는 CUDA가 사용 가능한 환경에서만 실행합니다.\n",
    "# ``torch.device`` 를 사용하여 tensor를 GPU 안팎으로 이동해보겠습니다.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # CUDA 장치 객체(device object)로\n",
    "    y = torch.ones_like(x, device=device)  # GPU 상에 직접적으로 tensor를 생성하거나\n",
    "    x = x.to(device)                       # ``.to(\"cuda\")`` 를 사용하면 됩니다.\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` 는 dtype도 함께 변경합니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
