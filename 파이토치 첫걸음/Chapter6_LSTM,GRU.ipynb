{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chapter6_LSTM,GRU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"ceY7CyM5m4Uo","colab_type":"code","outputId":"e9843c74-d197-4f55-d4c8-0afdfd336a58","executionInfo":{"status":"ok","timestamp":1573184940142,"user_tz":-540,"elapsed":6433,"user":{"displayName":"조경진","photoUrl":"","userId":"06712751099335327791"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["!rm -r data\n","import os \n","\n","try:\n","  os.mkdir(\"./data\")\n","except:\n","  pass\n","\n","!wget https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt -P ./data\n","# 학습할 데이터 불러오기\n","!pip install Unidecode\n","# Unidecode 없으면 install"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2019-11-08 03:48:57--  https://raw.githubusercontent.com/dmlc/web-data/master/mxnet/tinyshakespeare/input.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1115394 (1.1M) [text/plain]\n","Saving to: ‘./data/input.txt’\n","\n","\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n","\n","2019-11-08 03:48:57 (43.1 MB/s) - ‘./data/input.txt’ saved [1115394/1115394]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vfHdggrqmGJG","colab_type":"code","colab":{}},"source":["\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import unidecode\n","import string\n","import random\n","import re\n","import time, math\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7mTZmhTrLKa","colab_type":"code","colab":{}},"source":["# 사용될 HyperParameters\n","num_epochs = 2000\n","print_every = 100\n","plot_every = 10\n","chunk_len = 200\n","hidden_size = 100\n","batch_size = 1\n","num_layers = 1\n","embedding_size = 70\n","lr = 0.002"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aw5SvWEQmL5s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"3966fd0c-98b5-43fe-e439-dffa9489d0b3","executionInfo":{"status":"ok","timestamp":1573185033655,"user_tz":-540,"elapsed":990,"user":{"displayName":"조경진","photoUrl":"","userId":"06712751099335327791"}}},"source":["all_characters = string.printable\n","n_characters = len(all_characters)\n","print(all_characters)\n","print('num_chars', n_characters)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n","\r\u000b\f\n","num_chars 100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NV-PVKagmYv2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b55e5af8-4be8-41af-b300-68bd4bce599b","executionInfo":{"status":"ok","timestamp":1573185034779,"user_tz":-540,"elapsed":580,"user":{"displayName":"조경진","photoUrl":"","userId":"06712751099335327791"}}},"source":["file = unidecode.unidecode(open('./data/input.txt').read())\n","file_len = len(file)\n","print('file_len = ', file_len)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["file_len =  1115394\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IICzjBx0nYXP","colab_type":"code","colab":{}},"source":["# 모든 파일을 한번에 학습할수 없기때문에 일정한 크기로 잘라줘야한다\n","# 랜덤한 위치에서 시작해 일정 크기만큼의 문자열을 읽어오는 random_chunk() 라는 함수를 만들어줌\n","def random_chunk():\n","  start_index = random.randint(0,file_len- chunk_len)\n","  end_index = start_index + chunk_len + 1\n","  return file[start_index:end_index]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKoK-z3lvvHd","colab_type":"code","colab":{}},"source":["# 문자열을 입력값과 목표값으로 나누어준다\n","# random_chunk() 함수를 통해 랜덤한 문자열을 불러와 입력값과 목표값으로 나눠 리턴\n","def random_training_set():    \n","    chunk = random_chunk()\n","    inp = char_tensor(chunk[:-1])\n","    # 마지막 인덱스만 빼고 char_tensor 에 넣어줌\n","    target = char_tensor(chunk[1:])\n","    # 첫번째 인덱스만 빼고 넣어줌\n","    return inp, target"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KYT4_FAWn56r","colab_type":"code","colab":{}},"source":["# 일정 크기로 문자열을 읽어온 다음 이를 앞에서 저장해둔 출력 가능한 문자열 리스트를 통해 인덱스로 바꿔준다\n","def char_tensor(string):\n","  tensor = torch.zeros(len(string)).long()\n","  for c in range(len(string)):\n","    tensor[c] = all_characters.index(string[c])\n","  return tensor\n","\n","print(char_tensor('ABCdef'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FxJ87veCpeit","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.num_layers = num_layers\n","        self.embedding_size = embedding_size\n","\n","        self.encoder = nn.Embedding(input_size,embedding_size)\n","        # 총 단어의 개수, 임베딩 시킬 벡터의 차원\n","        # 알파벳이나 단어같은 기본 단위 요소들을 일정한 길이를 가지는 벡터공간에 투영시키는 것\n","        #self.rnn = nn.RNN(embedding_size,hidden_size,num_layers)\n","        self.rnn = nn.LSTM(embedding_size,hidden_size,num_layers)\n","        #self.rnn = nn.GRU(embedding_size, hidden_size , num_layers) # GRU방식\n","        self.decoder = nn.Linear(hidden_size,output_size)\n","        # 임베딩 하기전 의 데이터 형태로 돌려놓는 역할\n","\n","\n","    # def forward(self,input,hidden):\n","    #   out = self.encoder(input.view(1,-1))\n","    #   out,hidden = self.rnn(out,hidden)\n","    #   out = self.decoder(out.view(batch_size,-1))\n","    #   return out, hidden\n","\n","\n","    # def init_hidden(self):\n","    #   hidden = torch.zeros(self.num_layers,batch_size,hidden_size)\n","    #   return hidden\n","\n","    #LSTM version\n","    def forward(self,input,hidden,cell):\n","      out = self.encoder(input.view(batch_size,-1))\n","      out,(hidden,cell) = self.rnn(out,(hidden,cell))\n","      out = self.decoder(out.view(batch_size,-1))\n","      return out,hidden,cell\n","\n","    def init_hidden(self):\n","      hidden = torch.zeros(num_layers,batch_size,hidden_size)\n","      cell = torch.zeros(num_layers,batch_size,hidden_size)\n","      return hidden,cell\n","\n","# 클래스를 인스턴스화 \n","\n","#LSTM..\n","model = RNN(n_characters, embedding_size, hidden_size, n_characters,num_layers)\n","\n","# model = RNN(input_size=n_characters,\n","#             embedding_size = embedding_size,\n","#             hidden_size = hidden_size,\n","#             output_size = n_characters,\n","#             num_layers = 2)\n","\n","\n","# A 라는 문자열을 입력으로 주고 char_tensor를 이용해 텐서로 바꿔준다.\n","# 은식상태도 초기화\n","inp = char_tensor(\"A\")\n","hidden = model.init_hidden()\n","# 임베딩 값과 은식 상태 값을 전달해준다.\n","# 임베딩 차원이 문자열 크기와 다르기 때문에 RNN 노드의 결과값을 디코더를 통해 다시 맞춰줘야한다. \n","out,hidden = model(inp,hidden)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjhHKmCTsx-N","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","loss_func = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3gwPbIrvrDmN","colab_type":"code","colab":{}},"source":["for i in range(num_epochs):\n","  total = char_tensor(random_chunk())\n","  inp = total[:-1]\n","  label = total[:-1]\n","  hidden = model.init_hidden()\n","  loss = torch.tensor([0]).type(torch.FloatTensor)\n","\n","# 더이상 기울기 학습을 하지 못하게 함\n","  optimizer.zero_grad()\n","  for j in range(chunk_len-1):\n","    x = inp[j]\n","    # unsqueeze()함수는 인수로 받은 위치에 새로운 차원을 삽입한다.\n","    y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n","    y,hidden = model(x,hidden)\n","    loss += loss_func(y,y_)\n","\n","  loss.backward()\n","  optimizer.step()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"quuJbwjAr0MG","colab_type":"code","colab":{}},"source":["def test():\n","    start_str = \"b\"\n","    inp = char_tensor(start_str)\n","    hidden,cell = model.init_hidden()\n","    x = inp\n","\n","    print(start_str,end=\"\")\n","    for i in range(200):\n","        output,hidden,cell = model(x,hidden,cell)\n","\n","        output_dist = output.data.view(-1).div(0.8).exp()\n","        top_i = torch.multinomial(output_dist, 1)[0]\n","        predicted_char = all_characters[top_i]\n","\n","        print(predicted_char,end=\"\")\n","\n","        x = char_tensor(predicted_char)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A8Gx3nRXuroU","colab_type":"code","colab":{}},"source":["for i in range(num_epochs):\n","    inp,label = random_training_set()\n","    hidden,cell = model.init_hidden()\n","\n","    loss = torch.tensor([0]).type(torch.FloatTensor)\n","    optimizer.zero_grad()\n","    for j in range(chunk_len-1):\n","        x  = inp[j]\n","        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n","        y,hidden,cell = model(x,hidden,cell)\n","        loss += loss_func(y,y_)\n","\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if i % 100 == 0:\n","        print(\"\\n\",loss/chunk_len,\"\\n\")\n","        test()\n","        print(\"\\n\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_C4isrgPvgvS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}